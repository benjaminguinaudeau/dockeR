# dockeR

The aim of this package is to facilitate Web Scraping with Selenium. The package proposes the following tools: 
+ Creating a new container with Selenium Installed
+ Some basic tools allowing to get informations on docker containers (name, time, type, http ports, viewing ports)
+ Some basic Selenium function aimed at making webscraping easy

# Getting Docker installed

# Required Packages

```{r}
library(dplyr)
library(stringr)
library(purrr)
library(glue)

```

# Running a first container

```{r}

# First Container
create_container(image_src = "selenium/standalone-chrome-debug",
                 container_name = "test1")

# Seoncd Container
create_container(image_src = "selenium/standalone-chrome-debug",
                 container_name = "test2")

# Third Container
create_container(image_src = "selenium/standalone-chrome-debug",
                 container_name = "test3")

existing_containers()
running_containers()
stopped_containers()

stop_container("test1")
stopped_containers()
running_containers()


start_container("test1")
stopped_containers()
running_containers()


stop_container("test1", remove = T)
existing_containers()

remove_container("test2")
stop_container("test2")
remove_container("test2")

get_port("test3")
get_port("test3", filter_port = 4444) # HTTP
get_port("test3", filter_port = 5900) # Viewer
viewer("test3")

```

# To do

## Open a tty to interact within 
```{r}
system("docker exec -it test1 bash")
```

